{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a02ec11-ecfd-4655-b7de-02a99ad36a61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creación del dataset principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "456b900f-ee50-48ef-937f-202a40963ffe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Ejecutar query para obtener el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e53abbf-a70e-4173-8b89-b4543b4bcc8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dado que el dataset final tiene **más de 400 millones de filas**, **varias columnas de diversos tipos de datos** y un tamaño de alrededor de **20GB**,  se ha creado un data frame distribuido con **Spark** que contiene tal dataset, previamente almacenado en Azure Data Lake. Las consultas y creación de subconjuntos de datos para los algoritmos de Aprendizaje Automático se efectuarán con Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "069e5109-eb08-4745-9368-93ad0d8ff372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configurar Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "929e3558-6f5b-40b0-8302-f8fdfcdac5ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, col, regexp_extract, count\n",
    "\n",
    "# Iniciar sesión de Spark con configuración ajustada para 32GB RAM\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Preparación dataset para entrenamiento del modelo predictivo\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"24g\") \\\n",
    "    .config(\"spark.executor.memory\", \"24g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"64\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77a41d9e-8807-48a8-8a28-4bafabe0558a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cargar los archivos CSV en DataFrames de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc49fc20-0479-4c35-a307-075f9b3ba0df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definir la ubicación de los archivos\n",
    "base_path = f\"./data\"\n",
    "\n",
    "# Cargar los CSV en DataFrames\n",
    "df_admissions = spark.read.option(\"header\", \"true\").csv(f\"{base_path}/mimic4/admissions.csv\")\n",
    "df_labevents = spark.read.option(\"header\", \"true\").csv(f\"{base_path}/mimic4/labevents.csv\")\n",
    "df_diagnoses_icd = spark.read.option(\"header\", \"true\").csv(f\"{base_path}/mimic4/diagnoses_icd.csv\")\n",
    "df_d_icd_diagnoses = spark.read.option(\"header\", \"true\").csv(f\"{base_path}/mimic4/d_icd_diagnoses.csv\")\n",
    "df_icd_blocks = spark.read.option(\"header\", \"true\").csv(f\"{base_path}/mimic4/icd_blocks.csv\")\n",
    "df_patients = spark.read.option(\"header\", \"true\").csv(f\"{base_path}/mimic4/patients.csv\")\n",
    "\n",
    "# Registrar los DataFrames como tablas temporales en SparkSQL\n",
    "df_admissions.createOrReplaceTempView(\"admissions\")\n",
    "df_labevents.createOrReplaceTempView(\"labevents\")\n",
    "df_diagnoses_icd.createOrReplaceTempView(\"diagnoses_icd\")\n",
    "df_d_icd_diagnoses.createOrReplaceTempView(\"d_icd_diagnoses\")\n",
    "df_icd_blocks.createOrReplaceTempView(\"icd_blocks\")\n",
    "df_patients.createOrReplaceTempView(\"patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b19c56ce-23bc-4fa1-9eba-acd2eb5d27f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Ejecutar la consulta SQL en Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener datos de todos los ingresos, pruebas, diagnosticos y datos de pacientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "889d2c33-1a84-4528-9849-7dc5f6c92333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "  admissions.hadm_id AS id_ingreso,\n",
    "  labevents.itemid AS id_prueba,\n",
    "  diagnoses_icd.icd_code AS diagnostico_icd,\n",
    "  d_icd_diagnoses.long_title AS diagnostico_descripcion,\n",
    "  icd_blocks.icd_domain_code AS dominio_icd,\n",
    "  icd_blocks.domain_description AS dominio_descripcion,\n",
    "  patients.gender AS sexo,\n",
    "  patients.anchor_age AS edad,\n",
    "  admissions.marital_status AS estado_civil,\n",
    "  admissions.insurance AS tipo_seguro,\n",
    "  admissions.race AS grupo_poblacional,\n",
    "  admissions.hospital_expire_flag AS muerte_durante_ingreso\n",
    "FROM admissions\n",
    "INNER JOIN labevents\n",
    "  ON admissions.hadm_id = labevents.hadm_id\n",
    "INNER JOIN diagnoses_icd\n",
    "  ON admissions.hadm_id = diagnoses_icd.hadm_id\n",
    "INNER JOIN d_icd_diagnoses\n",
    "  ON diagnoses_icd.icd_code = d_icd_diagnoses.icd_code\n",
    "  AND diagnoses_icd.icd_version = d_icd_diagnoses.icd_version\n",
    "INNER JOIN icd_blocks\n",
    "  ON icd_blocks.icd_code = diagnoses_icd.icd_code\n",
    "INNER JOIN patients\n",
    "  ON patients.subject_id = admissions.subject_id\n",
    "WHERE diagnoses_icd.icd_version = 10\n",
    "AND patients.anchor_age >= 18\n",
    "AND labevents.hadm_id IS NOT NULL\n",
    "AND labevents.flag = 'abnormal'\n",
    "ORDER BY id_ingreso, id_prueba\n",
    "\"\"\"\n",
    "\n",
    "df_result = spark.sql(query)\n",
    "df_result.show(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73a6ea1b-bd02-48ae-b86f-ccb0b89515e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Guardar el resultado en formato Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "210d3196-2c81-4abd-8c20-909df8f86279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_path = f\"{base_path}/resultados/dataset_final.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b780d1d-370e-49b8-a79e-45fdb8dcc4bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_result.write.mode(\"overwrite\").parquet(output_path)\n",
    "print(f\"Los datos han sido almacenados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Creación del dataset",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
