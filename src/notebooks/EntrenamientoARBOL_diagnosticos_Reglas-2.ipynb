{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar el dataset y entrenar el modelo para el arbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ek4BHcr_1Amb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "96322582-7dbf-49f6-bf08-e9322dc37d1f"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y scikit-learn mlxtend imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPCIOAYN1S4r",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7c457c1f-546a-4c0a-e123-c69db5c27248"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3op2Z4E1xxh",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d21e3370-e4d8-41b8-905f-ed64465cec50"
   },
   "outputs": [],
   "source": [
    "!pip install mlxtend imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxNaAE4cqcOS",
    "outputId": "70242037-01f2-4ddf-bc57-69c09f11e3eb"
   },
   "outputs": [],
   "source": [
    "!pip install numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwrfHhybqDhm",
    "outputId": "e1ef72f7-2e50-4a1d-9d3e-670e7d2b34d0"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pip install pyspark[ml]==3.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pip install cudf-cu11 dask-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J32OvHGrrOS9",
    "outputId": "f5da5702-24be-4e1f-9adb-468a4e90530b"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import xgboost\n",
    "import sklearn\n",
    "\n",
    "print(\"Versión actual de scikit-learn:\", sklearn.__version__)\n",
    "print(f\"Versión de numpy: {numpy.__version__}\")\n",
    "print(f\"Versión de scipy: {scipy.__version__}\")\n",
    "print(f\"Versión de XGBoost: {xgboost.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSulZxwUKBS_"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whz8k0NqJypV"
   },
   "outputs": [],
   "source": [
    "ruta_rules = \"data/resultados/fpgrowth_rules.parquet\"\n",
    "ruta_diagnosticos = \"data/resultados/icd-10-cm-tabular-2025.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Detener sesión anterior\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Preparación dataset para entrenamiento del modelo predictivo\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "    .config(\"spark.executor.memory\", \"20g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer dataset de reglas en Parquet (formato optimizado para Spark)\n",
    "df_rules = spark.read.parquet(ruta_rules)\n",
    "print(\"Dataset reglas cargado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer dataset de diagnósticos en CSV\n",
    "df_diagnosticos = spark.read.csv(ruta_diagnosticos, header=True, inferSchema=True)\n",
    "print(\"Dataset diagnósticos cargado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "# Extraer los items de las columnas 'antecedent' y 'consequent'\n",
    "all_antecedents = df_rules.select(explode(col(\"antecedent\")).alias(\"diagnosis\"))\n",
    "all_consequents = df_rules.select(explode(col(\"consequent\")).alias(\"diagnosis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir antecedentes y consecuentes\n",
    "all_diagnoses = all_antecedents.union(all_consequents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "# Filtrar los valores que cumplen con el patrón ICD-10\n",
    "diagnoses = all_diagnoses.filter(regexp_extract(col(\"diagnosis\"), r'^[A-Za-z]\\d{2}$', 0) != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los diagnósticos únicos\n",
    "unique_diagnoses = diagnoses.select(\"diagnosis\").distinct()\n",
    "total_unique_diagnoses = unique_diagnoses.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Diagnósticos únicos encontrados: {total_unique_diagnoses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Frecuencia de cada diagnóstico\n",
    "from pyspark.sql.functions import desc, count\n",
    "diagnosis_counts = diagnoses.groupBy(\"diagnosis\").agg(count(\"*\").alias(\"frequency\")).orderBy(desc(\"frequency\")) \n",
    "diagnosis_counts.show(truncate=False, n=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_counts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir unique_diagnoses en un DataFrame con nombre de columna \"icd_code\"\n",
    "df_diagnosticos_reglas = unique_diagnoses.withColumnRenamed(\"diagnosis\", \"icd_domain_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnosticos_reglas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnosticos_reglas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnosticos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnosticos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el JOIN para mantener solo las coincidencias en 'icd_code'\n",
    "df_diagnosticos_final = (\n",
    "    df_diagnosticos_reglas\n",
    "    .join(df_diagnosticos, on=\"icd_domain_code\", how=\"left\")\n",
    "    .select(\"icd_domain_code\", \"domain_description\")  # Selecciona solo las columnas necesarias\n",
    "    .distinct()  # Mantiene solo valores únicos\n",
    "    .coalesce(1)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnosticos_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_counts_desc = df_diagnosticos_final.merge(\n",
    "    diagnosis_counts.toPandas(), \n",
    "    left_on=\"icd_domain_code\", \n",
    "    right_on=\"diagnosis\", \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_counts_desc = diagnosis_counts_desc.drop(columns=[\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_counts_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_counts_desc = diagnosis_counts_desc.sort_values(by=\"frequency\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnosticos_final.to_csv(\"data/resultados/df_diagnosticos_REGLAS.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Archivo guardado como data/resultados/df_diagnosticos_REGLAS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_counts_desc.to_csv(\"data/resultados/df_diagnosticos_REGLAS_frecuencias.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Archivo guardado como data/resultados/df_diagnosticos_REGLAS_frecuencias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ruta_diagnosticos_reglas = \"data/resultados/df_diagnosticos_REGLAS.csv\"\n",
    "df_diagnosticos_reglas = pd.read_csv(ruta_diagnosticos_reglas)\n",
    "df_diagnosticos_reglas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5TQffSBVIjE"
   },
   "source": [
    "# Modelo diagnosticos reglas de asociacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "YsOj4Xx3VOvL",
    "outputId": "4a5a3a2f-29fc-4ce8-acac-74104bdee5f3"
   },
   "outputs": [],
   "source": [
    "ruta_arbol = \"data/resultados/arbol_preprocesado.parquet\"\n",
    "ruta_diagnosticos_reglas = \"data/resultados/df_diagnosticos_REGLAS.csv\"\n",
    "\n",
    "# Leer el archivos\n",
    "df_procesado = pd.read_parquet(ruta_arbol)\n",
    "df_diagnosticos_reglas = pd.read_csv(ruta_diagnosticos_reglas)\n",
    "\n",
    "# Ver las primeras filas para comprobar que se cargó correctamente\n",
    "df_procesado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_procesado.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de dominios de patologías más representativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el decidir con que dominios ICD de patologias se trabajan para entrenar el modelo se sigue el criterio de la **Cobertura**.\n",
    "\n",
    "Sea $D = \\{ d_1, d_2, \\dots, d_n \\} $ el conjunto de dominios ICD, cada uno con un valor de *domain_description* y $\\text{freq}(d_i)$ su frecuencia. Se tiene que:\n",
    "\n",
    "1. **Total de casos** (suma de todas las frecuencias):\n",
    "   $$\n",
    "   T = \\sum_{i=1}^{n} \\text{freq}(d_i)\n",
    "   $$\n",
    "\n",
    "2. **Se ordenan los dominios de mayor a menor frecuencia**:\n",
    "   $$\n",
    "   \\text{freq}(d_1) \\geq \\text{freq}(d_2) \\geq \\dots \\geq \\text{freq}(d_n).\n",
    "   $$\n",
    "\n",
    "3. **Se define un umbral** $ \\tau \\geq 1 $.  \n",
    "   El subconjunto $ S(\\tau) $ de bloques *seleccionados* es:\n",
    "   $$\n",
    "   S(\\tau) = \\{ d_i \\mid \\text{freq}(d_i) \\geq \\tau \\}.\n",
    "   $$\n",
    "\n",
    "4. **El número de dominios seleccionados** es $|S(\\tau)|$.\n",
    "\n",
    "5. **La cobertura en términos de casos**:\n",
    "   $$\n",
    "   \\text{Cobertura}(\\tau) = \\frac{\\sum_{d_i \\in S(\\tau)} \\text{freq}(d_i)}{T}.\n",
    "   $$\n",
    "\n",
    "Conforme $\\tau $ aumenta, $|S(\\tau)|$ tiende a disminuir (se descartan más clases de baja frecuencia), pero en general, también se descartan relativamente pocos casos si la cola de baja frecuencia es pequeña en proporción al total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fijar $\\tau$ se ha de definir un **porcentaje mínimo** de cobertura $\\alpha$ (por ejemplo, 95%) y escoger la menor $\\tau$ tal que:\n",
    "\n",
    "$$\n",
    "\\text{Cobertura}(\\tau) \\geq \\alpha.\n",
    "$$\n",
    "\n",
    "Con esto, se garantiza que se están reteniendo $\\alpha \\times 100\\%$ de los casos totales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto si se fija un $\\alpha=99$, se tiene que $\\tau$ es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    diagnosis_counts_desc\n",
    "    .groupby(\"domain_description\", as_index=False)\n",
    "    .agg({\"frequency\": \"sum\"})\n",
    "    .sort_values(by=\"frequency\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "total = grouped_df['frequency'].sum()\n",
    "alpha = 0.99\n",
    "\n",
    "# Calcular la freq acumulada y la cobertura acumulada\n",
    "grouped_df['cumulative_freq'] = grouped_df['frequency'].cumsum()\n",
    "grouped_df['coverage'] = grouped_df['cumulative_freq'] / total\n",
    "\n",
    "# Localizar la fila donde se alcanza (o supera) esa cobertura\n",
    "mask = grouped_df['coverage'] >= alpha\n",
    "if mask.any():\n",
    "    # Tomar el primer índice donde coverage >= 0.99\n",
    "    idx = mask.idxmax()\n",
    "    # Frecuencia de la clase en esa fila\n",
    "    tau = grouped_df.loc[idx, 'frequency']\n",
    "    print(f\"Para cubrir al menos el {alpha*100}% de los casos, un tau de ~{tau} es apropiado.\")\n",
    "else:    \n",
    "    print(\"No se alcanza esa cobertura con los datos actuales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, los **dominios de patologias seleccionados** para entrenar el modelo predictivo son todos aquellos con una **frecuencia** de diagnóstico en el consecuente de las reglas mayor o igual a **27259**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv(\"data/resultados/df_diagnosticos_REGLAS_agrupados_frecuencias.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Archivo guardado como data/resultados/df_diagnosticos_REGLAS_agrupados_frecuencias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_99 = grouped_df.query('frequency>=27259')\n",
    "grouped_df_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_99.to_csv(\"data/resultados/df_diagnosticos_REGLAS_agrupados_frecuencias_99.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Archivo guardado como data/resultados/df_diagnosticos_REGLAS_agrupados_frecuencias_99.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos_seleccionados = df_diagnosticos_final.merge(grouped_df_99[[\"domain_description\"]], \n",
    "                                    on=\"domain_description\", \n",
    "                                    how=\"inner\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos_seleccionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "Mz9Upo0pVRlG",
    "outputId": "569c179c-1408-4b69-ec34-915eba4a256f"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Identificar todas las columnas de diagnósticos en df_procesado\n",
    "columnas_diagnosticos = [col for col in df_procesado.columns if re.match(r\"^[A-Z]\\d{2}$\", col)]\n",
    "\n",
    "# Filtrar solo los diagnósticos seleccionados dentro de las columnas disponibles en df_procesado\n",
    "diagnosticos_filtrados = [col for col in columnas_diagnosticos if col in diagnosticos_seleccionados[\"icd_domain_code\"].tolist()]\n",
    "\n",
    "# Identificar los parámetros bioquímicos (columnas que empiezan con \"prueba_\")\n",
    "columnas_bioquimicas = [col for col in df_procesado.columns if col.startswith(\"prueba_\")]\n",
    "\n",
    "# Identificar otras variables explicativas (ni diagnósticos ni pruebas bioquímicas)\n",
    "otras_explicativas = [\n",
    "    col for col in df_procesado.columns if col not in (columnas_diagnosticos + columnas_bioquimicas)\n",
    "]\n",
    "\n",
    "# Conservar las variables anteriores, las pruebas bioquímicas y los diagnósticos filtrados\n",
    "columnas_a_conservar = otras_explicativas + columnas_bioquimicas + diagnosticos_filtrados\n",
    "\n",
    "df_procesado_filtrado = df_procesado[columnas_a_conservar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Crear diccionario de renombrado de columnas\n",
    "icds_dominios = dict(zip(diagnosticos_seleccionados[\"icd_domain_code\"].values, \n",
    "                         diagnosticos_seleccionados[\"domain_description\"].values))\n",
    "\n",
    "#  Renombrar las columnas del DataFrame\n",
    "df_procesado_filtrado = df_procesado_filtrado.rename(columns=lambda x: icds_dominios.get(x, x), inplace=False)\n",
    "\n",
    "# Identificar **únicamente** las columnas repetidas\n",
    "columnas_repetidas = set([col for col in df_procesado_filtrado.columns if df_procesado_filtrado.columns.tolist().count(col) > 1])\n",
    "\n",
    "# Crear diccionario de agrupación **solo para las repetidas**\n",
    "columnas_agrupadas = defaultdict(list)\n",
    "for col in columnas_repetidas:\n",
    "    columnas_agrupadas[col] = [c for c in df_procesado_filtrado.columns if c == col]\n",
    "\n",
    "df_fusionado = df_procesado_filtrado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar OR bitwise a las columnas repetidas y fusionarlas\n",
    "for col, col_list in columnas_agrupadas.items():\n",
    "    df_fusionado[col] = np.bitwise_or.reduce(df_procesado_filtrado[col_list].values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionado = df_fusionado.loc[:, ~df_fusionado.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado_filtrado = df_fusionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diagnosticos_seleccionados[\"domain_description\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados\n",
    "print(f\"Columnas originales: {df_procesado.shape[1]}\")\n",
    "print(f\"Diagnósticos retenidos: {len(diagnosticos_seleccionados['domain_description'].unique())} de {len(columnas_diagnosticos)}\")\n",
    "print(f\"Parámetros bioquímicos retenidos: {len(columnas_bioquimicas)}\")\n",
    "print(f\"Otras variables explicativas retenidas: {len(otras_explicativas)}\")\n",
    "print(f\"Nuevo total de columnas tras agrupar en bloques ICD: {df_procesado_filtrado.shape[1]}\")\n",
    "\n",
    "df_procesado_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Y1w7a0eZM5n",
    "outputId": "9fbae665-8edc-45aa-d055-a112836c5438"
   },
   "outputs": [],
   "source": [
    "ruta_guardado = \"data/resultados/df_procesado_filtrado_para_arbol.csv\"\n",
    "df_procesado_filtrado.to_csv(ruta_guardado, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Archivo guardado en: {ruta_guardado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar dataset para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "E0YuInQumA9y",
    "outputId": "f535f635-61d8-47d9-f25b-ce16233df768"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ruta_df_procesado_filtrado = \"data/resultados/df_procesado_filtrado_para_arbol.csv\"\n",
    "\n",
    "df_procesado_filtrado = pd.read_csv(ruta_df_procesado_filtrado)\n",
    "df_procesado_filtrado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de dataset procesado para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado_filtrado.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir el subconjunto de columnas para analizar\n",
    "columnas_seleccionadas = df_procesado_filtrado.columns[-10:]\n",
    "\n",
    "# Contar la frecuencia de cada categoría en las columnas seleccionadas\n",
    "frecuencias = df_procesado_filtrado[columnas_seleccionadas].sum().sort_values(ascending=False)\n",
    "\n",
    "# Estilo ggplot-like\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Configuración del gráfico\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(frecuencias.index, frecuencias.values, color=\"#4C72B0\", alpha=0.85, edgecolor='black')\n",
    "\n",
    "ax.set_facecolor(\"#F0F0F0\")  # Fondo gris claro\n",
    "ax.spines[\"top\"].set_visible(False)   # Eliminar bordes superiores\n",
    "ax.spines[\"right\"].set_visible(False) # Eliminar bordes derechos\n",
    "\n",
    "# Etiquetas y título con mejor tipografía\n",
    "ax.set_xlabel(\"Bloques ICD (One-Hot Encoding)\", fontsize=14, labelpad=10)\n",
    "ax.set_ylabel(\"Frecuencia\", fontsize=14, labelpad=10)\n",
    "ax.set_title(\"Distribución de Frecuencias de Bloques ICD de Patologías\", fontsize=16, pad=15)\n",
    "\n",
    "# Rotación y alineación de etiquetas\n",
    "plt.xticks(rotation=90, ha=\"right\", fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Cuadrícula sutil en eje Y\n",
    "ax.yaxis.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data profiling para detectar posibles sesgos y desbalanceos\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(\n",
    "    df_procesado_filtrado,\n",
    "    title=\"Reporte EDA (minimal)\",\n",
    "    minimal=True\n",
    ")\n",
    "profile.to_file(\"data/resultados/EDA_informe.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir, Optimizar hiperparámetros y entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llnGH9okVxkY",
    "outputId": "5fcb4731-da21-4c84-cc03-e0f2e9949430"
   },
   "outputs": [],
   "source": [
    "columnas_y = columnas_seleccionadas\n",
    "\n",
    "# Crear 'Y' con los diagnósticos\n",
    "Y = df_procesado_filtrado[columnas_y]\n",
    "\n",
    "# Crear 'X' eliminando las columnas de diagnóstico\n",
    "X = df_procesado_filtrado.drop(columns=columnas_y)\n",
    "\n",
    "print(f\"Tamaño de X: {X.shape}\")\n",
    "print(f\"Tamaño de Y: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RJED_SIYSVt"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, hamming_loss, jaccard_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdT6PJfpYTLR"
   },
   "outputs": [],
   "source": [
    "# Dividir en 80% entrenamiento y 20% prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba previa de uso correcto de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Crear dataset de prueba\n",
    "X_dummy = np.random.rand(100000, 50)\n",
    "y_dummy = np.random.randint(2, size=100000)\n",
    "\n",
    "# Configuración de CPU\n",
    "cpu_model = xgb.XGBClassifier(tree_method=\"hist\", device=\"cpu\")\n",
    "\n",
    "# Configuración de GPU\n",
    "gpu_model = xgb.XGBClassifier(tree_method=\"hist\", device=\"cuda\")\n",
    "\n",
    "# Entrenar con CPU\n",
    "start_cpu = time.time()\n",
    "cpu_model.fit(X_dummy, y_dummy)\n",
    "end_cpu = time.time()\n",
    "\n",
    "# Entrenar con GPU\n",
    "start_gpu = time.time()\n",
    "gpu_model.fit(X_dummy, y_dummy)\n",
    "end_gpu = time.time()\n",
    "\n",
    "# Resultados\n",
    "print(f\"Tiempo de entrenamiento en CPU: {end_cpu - start_cpu:.2f} segundos\")\n",
    "print(f\"Tiempo de entrenamiento en GPU: {end_gpu - start_gpu:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros mediante búsqueda estocástica Halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Diccionario donde almacenar el mejor modelo entrenado para cada etiqueta\n",
    "best_models_per_label = {}\n",
    "\n",
    "# Param distributions para la búsqueda\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.5, 0.7, 0.9],\n",
    "    \"colsample_bytree\": [0.4, 0.6, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.001, 0.01, 0.1, 1],  # Regularización L1\n",
    "    \"reg_lambda\": [0, 0.001, 0.01, 0.1, 1]  # Regularización L2   \n",
    "}\n",
    "\n",
    "# Calcular min_resources para HalvingRandomSearch\n",
    "N = len(X_train)\n",
    "# Calcular número total de combinaciones\n",
    "M = np.prod([len(v) for v in param_dist.values()])\n",
    "# Factor de reducción\n",
    "F = 3 \n",
    "# Calcular número de iteraciones necesarias\n",
    "K = int(np.floor(np.log(M) / np.log(F))) \n",
    "# Calcular min_resources\n",
    "min_resources = max(5000, N // (F ** K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar por cada dominio ICD\n",
    "for label in columnas_seleccionadas.to_list():\n",
    "    print(f\"\\n=== Entrenando etiqueta: {label} ===\")\n",
    "\n",
    "    # Extraer y_train_label e y_test_label\n",
    "    y_train_label = Y_train[label]\n",
    "    y_test_label = Y_test[label]\n",
    "\n",
    "    # Calcular scale_pos_weight específico\n",
    "    positives = np.sum(y_train_label == 1)\n",
    "    negatives = np.sum(y_train_label == 0)\n",
    "    if positives == 0:\n",
    "        # Si no hay positivos en train, no se puede entrenar (o se ignora la etiqueta)\n",
    "        print(f\"Etiqueta {label}: no hay positivos en train. Se omite.\")\n",
    "        continue\n",
    "\n",
    "    spw = negatives / positives\n",
    "\n",
    "    # Definir un XGBClassifier base con este scale_pos_weight\n",
    "    xgb_clf = XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=spw, # Para el desbalanceo de dominios\n",
    "        random_state=42,\n",
    "        device=\"cuda\",\n",
    "        tree_method=\"hist\",  \n",
    "    )\n",
    "\n",
    "    # Búsqueda de hiperparámetros con HalvingRandomSearch\n",
    "    search = HalvingRandomSearchCV(\n",
    "        estimator=xgb_clf,\n",
    "        param_distributions=param_dist,\n",
    "        factor=F,\n",
    "        resource='n_samples',\n",
    "        min_resources=min_resources,\n",
    "        cv=3,\n",
    "        scoring='f1_macro',\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    # Entrenar\n",
    "    search.fit(X_train, y_train_label)\n",
    "    print(\"Mejores hiperparámetros:\", search.best_params_)\n",
    "\n",
    "    # Mejor modelo\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    # Guardar el modelo en el diccionario\n",
    "    best_models_per_label[label] = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar submodelos binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_models_per_label, \"data/resultados/xgb_binary_models_per_label.pkl\")\n",
    "print(\"Guardado en data/resultados/xgb_binary_models_per_label.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar cada submodelo en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Arrays para reconstruir las predicciones globales (0/1)\n",
    "Y_pred = np.zeros_like(Y_test.values)  # shape: (num_samples_test, num_labels)\n",
    "\n",
    "# Arrays para reconstruir las probabilidades\n",
    "Y_proba = np.zeros_like(Y_test.values, dtype=float)\n",
    "\n",
    "# Lista para guardar las métricas de cada modelo/etiqueta\n",
    "metricas_list = []\n",
    "\n",
    "for i, label in enumerate(columnas_seleccionadas.to_list()):\n",
    "    if label not in best_models_per_label:\n",
    "        # Se omitió la etiqueta si no había positivos en train\n",
    "        continue\n",
    "\n",
    "    model_label = best_models_per_label[label]\n",
    "\n",
    "    # Predicciones 0/1\n",
    "    Y_pred_label = model_label.predict(X_test)  # array con 0 ó 1\n",
    "    Y_pred[:, i] = Y_pred_label\n",
    "\n",
    "    # Probabilidades de la clase 1 (columna 1 de predict_proba)\n",
    "    y_proba_label = model_label.predict_proba(X_test)[:, 1]\n",
    "    Y_proba[:, i] = y_proba_label\n",
    "\n",
    "    ### Cálculo de métricas\n",
    "    # Datos reales de test\n",
    "    y_true_label = Y_test[label].values\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    bal_acc = balanced_accuracy_score(y_true_label, Y_pred_label)\n",
    "\n",
    "    # F1 (para la clase 1)\n",
    "    f1_lbl = f1_score(y_true_label, Y_pred_label, average='binary', zero_division=0)\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true_label, y_proba_label)\n",
    "\n",
    "    # Precision-Recall AUC (equivalente a average_precision_score)\n",
    "    pr_auc = average_precision_score(y_true_label, y_proba_label)\n",
    "\n",
    "    # Accuracy “clásica” (opcional)\n",
    "    acc_label = accuracy_score(y_true_label, Y_pred_label)\n",
    "\n",
    "    ### Imprimir métricas\n",
    "    print(f\"\\n=== Etiqueta: {label} ===\")\n",
    "    print(f\"   Balanced Accuracy: {bal_acc:.4f}\")\n",
    "    print(f\"   F1 score (binary): {f1_lbl:.4f}\")\n",
    "    print(f\"   ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"   PR AUC: {pr_auc:.4f}\")\n",
    "    print(f\"   Accuracy (clásica): {acc_label:.4f}\")\n",
    "\n",
    "    # Imprimir un classification_report:\n",
    "    print(classification_report(y_true_label, Y_pred_label, zero_division=0))\n",
    "\n",
    "    ### Guardar métricas en nuestra lista\n",
    "    metricas_list.append({\n",
    "        'etiqueta': label,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'f1_score': f1_lbl,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'accuracy': acc_label\n",
    "    })\n",
    "\n",
    "    ### Gráfica ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true_label, y_proba_label)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label=\"Random\")\n",
    "    plt.title(f\"ROC Curve - {label}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "    ### Gráfica Precision-Recall\n",
    "    precision, recall, _ = precision_recall_curve(y_true_label, y_proba_label)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall, precision, label=f\"PR (AUC={pr_auc:.2f})\")\n",
    "    plt.title(f\"Precision-Recall Curve - {label}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "labels = columnas_seleccionadas.to_list()  # tus etiquetas (ej. 10 o 15)\n",
    "n_labels = len(labels)\n",
    "\n",
    "fig, axs = plt.subplots(n_labels, 2, figsize=(10, 5*n_labels))\n",
    "# axs[i, 0] => gráfico ROC de la etiqueta i\n",
    "# axs[i, 1] => gráfico PR de la etiqueta i\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    # Si omitiste la etiqueta en el entrenamiento, sigue\n",
    "    if label not in best_models_per_label:\n",
    "        continue\n",
    "\n",
    "    # Modelo y datos\n",
    "    model_label = best_models_per_label[label]\n",
    "    y_true = Y_test[label].values\n",
    "    y_proba = model_label.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcular datos ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "    # Calcular datos PR\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "\n",
    "    # --- Gráfico ROC ---\n",
    "    axs[i, 0].plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.2f})\")\n",
    "    axs[i, 0].plot([0,1],[0,1],'r--', label=\"Random\")\n",
    "    axs[i, 0].set_title(f\"ROC - {label}\")\n",
    "    axs[i, 0].set_xlabel(\"False Positive Rate\")\n",
    "    axs[i, 0].set_ylabel(\"True Positive Rate\")\n",
    "    axs[i, 0].legend(loc=\"best\")\n",
    "\n",
    "    # --- Gráfico PR ---\n",
    "    axs[i, 1].plot(recall, precision, label=f\"PR (AUC={pr_auc:.2f})\")\n",
    "    axs[i, 1].set_title(f\"Precision-Recall - {label}\")\n",
    "    axs[i, 1].set_xlabel(\"Recall\")\n",
    "    axs[i, 1].set_ylabel(\"Precision\")\n",
    "    axs[i, 1].legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de modelos con sus métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas_styled = (\n",
    "    df_metricas\n",
    "    .style\n",
    "    .format(precision=4)\n",
    "    .hide(axis=\"index\")\n",
    "    .background_gradient(cmap='Greens', subset=['balanced_accuracy','f1_score','roc_auc','pr_auc','accuracy'])\n",
    "    .set_caption(\"Métricas por Etiqueta (bloque ICD de patologías)\")\n",
    ")\n",
    "\n",
    "df_metricas_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelo, verificar predicción de probabilidades y explicabilidad del modelo (valores SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models = joblib.load(\"data/resultados/xgb_binary_models_per_label.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi_label_proba(loaded_models, X_new):\n",
    "    \"\"\"\n",
    "    Devuelve un diccionario donde cada clave es una descripcion de bloque ICD y el valor la probabilidad del bloque ICD de patologia.\n",
    "\n",
    "    \"\"\"\n",
    "    predictions_proba = {}\n",
    "    for label, model in loaded_models.items():\n",
    "        # predict_proba => shape (n_samples, 2), tomamos la col. 1\n",
    "        y_pred_proba_label = model.predict_proba(X_new)[:, 1]\n",
    "        predictions_proba[label] = y_pred_proba_label\n",
    "    return predictions_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(loaded_models):\n",
    "    \"\"\"\n",
    "    Para cada modelo XGBoost, extrae la importancia global de features,\n",
    "    usando get_booster().get_score(importance_type='gain').\n",
    "    Retorna un dict: { label: dict_importancia }.\n",
    "    \"\"\"\n",
    "    feature_importance_dict = {}\n",
    "    for label, model in loaded_models.items():\n",
    "        booster = model.get_booster()\n",
    "        importance_dict = booster.get_score(importance_type=\"gain\")\n",
    "        feature_importance_dict[label] = importance_dict\n",
    "    return feature_importance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def get_shap_values_with_features(loaded_models, X_new):\n",
    "    \"\"\"\n",
    "    Calcula los SHAP values para cada modelo (etiqueta) y retorna:\n",
    "        {\n",
    "          etiqueta: [\n",
    "            { \"feature_1\": shap_value_1, \"feature_2\": shap_value_2, ... },  # para la fila 0\n",
    "            { ... },                                                        # para la fila 1\n",
    "            ...\n",
    "          ],\n",
    "          ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    shap_dict = {}\n",
    "    feature_names = list(X_new.columns)\n",
    "\n",
    "    for label, model in loaded_models.items():\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        # shap_values => array shape (N, num_features)\n",
    "        shap_values = explainer.shap_values(X_new)\n",
    "\n",
    "        # Convertir cada fila (i) en un dict { feature_name: shap_value }\n",
    "        shap_rows = []\n",
    "        for i in range(shap_values.shape[0]):\n",
    "            row_dict = {}\n",
    "            for j, col_name in enumerate(feature_names):\n",
    "                # Convertir a float pura si deseas evitar tipos float32\n",
    "                row_dict[col_name] = float(shap_values[i, j])\n",
    "            shap_rows.append(row_dict)\n",
    "\n",
    "        shap_dict[label] = shap_rows\n",
    "\n",
    "    return shap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[[99]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paciente_ejemplo = X_test.iloc[[99]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilídades\n",
    "patology_probabilities = predict_multi_label_proba(loaded_models, paciente_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia global\n",
    "feature_imp = get_feature_importance(loaded_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores SHAP (explicación local)\n",
    "shap_dict = get_shap_values_with_features(loaded_models, paciente_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convertir los valores del diccionario a listas\n",
    "patology_probabilities_json = {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in patology_probabilities.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== PROBABILIDADES ===\")\n",
    "# Imprimir el diccionario en formato JSON\n",
    "print(json.dumps(patology_probabilities_json, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_json = {}\n",
    "for label, imp_dict in feature_imp.items():\n",
    "    new_imp = {k: float(v) for k, v in imp_dict.items()}\n",
    "    feature_importance_json[label] = new_imp\n",
    "    \n",
    "print(\"=== FEATURE IMPORTANCE ===\")\n",
    "print(json.dumps(feature_importance_json, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "shap_values_json = {\n",
    "    label: mat.tolist() if isinstance(mat, np.ndarray) else mat\n",
    "    for label, mat in shap_dict.items()\n",
    "}\n",
    "\n",
    "print(\"=== SHAP VALUES ===\")\n",
    "print(json.dumps(shap_values_json, indent=4))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
